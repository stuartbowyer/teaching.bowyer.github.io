{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://teaching.bowyer.io/SDSAI/0/img/IMPERIAL_logo_RGB_Blue_2024.svg\" alt=\"Imperial Logo\" width=\"500\"/><br /><br />\n",
    "\n",
    "Neural Networks and Deep Learning\n",
    "==============\n",
    "### SURG70098 - Surgical Data Science and AI\n",
    "### Stuart Bowyer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Intended Learning Outcomes\n",
    "1.  Understand the concept behind neural networks and how they 'learn'\n",
    "1.  Be able to build simple neural networks to address regression and classification problems\n",
    "1.  Be aware of the limitations and challenges of neural networks and where to look to address them\n",
    "1.  Have a preliminary understanding of what deep learning is and what it can be used for\n",
    "1.  Be able to understand hyperparameter selection and optimisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MIMIC Dataset\n",
    "The following code will load the datasets used in this lecture notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "%pip install pandas_gbq\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_gbq\n",
    "\n",
    "project_id = 'mimic-project-439314'  # @param {type:\"string\"}\n",
    "\n",
    "df_day1_vitalsign = pandas_gbq.read_gbq(\"\"\"\n",
    "  SELECT\n",
    "    *,\n",
    "    (dod IS NOT NULL) AND (dod <= dischtime) AS mortality,\n",
    "    weight / POWER(height/100, 2) > 30 AS obese\n",
    "  FROM `physionet-data.mimiciv_derived.first_day_vitalsign`\n",
    "  LEFT JOIN (\n",
    "    SELECT\n",
    "      subject_id,\n",
    "      stay_id,\n",
    "      gender,\n",
    "      race,\n",
    "      dischtime,\n",
    "      admission_age,\n",
    "      dod\n",
    "    FROM\n",
    "      `physionet-data.mimiciv_derived.icustay_detail`\n",
    "  )\n",
    "  USING(subject_id, stay_id)\n",
    "  LEFT JOIN (\n",
    "    SELECT\n",
    "      stay_id,\n",
    "      AVG(weight) as weight\n",
    "    FROM\n",
    "      `physionet-data.mimiciv_derived.weight_durations`\n",
    "    GROUP BY\n",
    "      stay_id\n",
    "  )\n",
    "  USING(stay_id)\n",
    "  LEFT JOIN (\n",
    "    SELECT\n",
    "      stay_id,\n",
    "      CAST(AVG(height) AS FLOAT64) AS height\n",
    "    FROM\n",
    "      `physionet-data.mimiciv_derived.height`\n",
    "    GROUP BY\n",
    "      stay_id\n",
    "  )\n",
    "  USING(stay_id)\n",
    "  WHERE heart_rate_mean IS NOT NULL\n",
    "\"\"\", project_id=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recap Supervised Learning\n",
    "*   Last week, we studied a few methods for supervised learning, all of these have some limitations\n",
    "    *   All methods involve some assumptions about model structure (e.g. linearity, mapped linearity)\n",
    "    *   KNN and SVM do not scale well to very large data sets or high dimensionality\n",
    "    *   Linear and logistic regression require feature engineering \n",
    "    *   Decision trees are prone to overfitting\n",
    "    *   And more..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural Networks\n",
    "*   Neural networks are a machine learning method that aims to overcome these issues\n",
    "*   Particularly with respect to:\n",
    "    *   Large data\n",
    "    *   High-dimensionality data\n",
    "    *   Complex interdependent data\n",
    "    *   (Unstructured data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bioinspiration\n",
    "*   These models were created to mimic the function of biological neurons\n",
    "*   By combining many neurons they are able to \n",
    "*   In reality, the aritifical neural networks are quite different from biological neural networks; however, they are very effective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Artifical Neurons\n",
    "Neural networks are made up from multiple artificial neurons\n",
    "\n",
    "![Artificial neuron image](https://teaching.bowyer.io/SDSAI/5/img/Illustrations-SDSAI-05_Artifical-Neuron.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Activation Functions\n",
    "*   Activation functions are a critical component of the neural network\n",
    "*   They produce non-linearity\n",
    "*   Therefore, allow it to model complex relationships\n",
    "*   There are a range of functions\n",
    "\n",
    "![Activation function illustration](https://teaching.bowyer.io/SDSAI/5/img/Illustrations-SDSAI-05_Activation-Functions.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quick Exercise - Artificial Neuron Worked Example\n",
    "For a three input neuron with the following input values and parameters, can you calculate (with simple Python) the output value of the neuron for the input `A Values` and the `B Values`?\n",
    "\n",
    "You should get a separate output value for each input set\n",
    "\n",
    "### Parameters\n",
    "| Parameter | Value |\n",
    "| --------- | ----- |\n",
    "| weight 1  | 0.5   |\n",
    "| weight 2  | 1.7   |\n",
    "| weight 3  | 0.001 |\n",
    "| bias      | -52   |\n",
    "| Activation function | ReLU |\n",
    "\n",
    "### Inputs\n",
    "| Input     | A Values  | B Values  |\n",
    "| --------- | --------- | --------- |\n",
    "| input 1   | 65 kg     | 82 kg     |\n",
    "| input 2   | 1.7 m     | 1.85 m    |\n",
    "| input 3   | 8200 c/uL | 9800 c/uL |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Possible Python Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuron output for A is 0\n",
      "Neuron output for B is 1.9450000000000074\n"
     ]
    }
   ],
   "source": [
    "w1 = 0.5\n",
    "w2 = 1.7\n",
    "w3 = 0.001\n",
    "bias = -52\n",
    "\n",
    "def relu(x):\n",
    "    if (x < 0):\n",
    "        return(0)\n",
    "    return(x)\n",
    "\n",
    "va1 = 65\n",
    "va2 = 1.7\n",
    "va3 = 8200\n",
    "\n",
    "vb1 = 82\n",
    "vb2 = 1.85\n",
    "vb3 = 9800\n",
    "\n",
    "output_a = relu(w1 * va1 + w2 * va2 + w3 * va3 + bias)\n",
    "output_b = relu(w1 * vb1 + w2 * vb2 + w3 * vb3 + bias)\n",
    "\n",
    "print(f'Neuron output for A is {output_a}')\n",
    "print(f'Neuron output for B is {output_b}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Neural Network\n",
    "*   An assembly of artificial neurons in a network structure\n",
    "*   Neurons are grouped into layers of three different types\n",
    "\n",
    "![Simple artificial neural network](https://teaching.bowyer.io/SDSAI/5/img/Illustrations-SDSAI-05_ANN.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why Neural Networks Work\n",
    "*   Each individual neuron can model a simple activation function\n",
    "*   By combining them in this structure, the combination of simple activation functions can model non-linear and complex relationships\n",
    "\n",
    "| Training | Predicting |\n",
    "| - | - |\n",
    "| <img src=\"https://upload.wikimedia.org/wikipedia/commons/0/0c/Simplified_neural_network_training_example.svg\" alt=\"Description of Image\" style=\"width: 450px; display: block; margin: 0 auto;\"> | <img src=\"https://upload.wikimedia.org/wikipedia/commons/b/b7/Simplified_neural_network_example.svg\" alt=\"Description of Image\" style=\"width: 450px; display: block; margin: 0 auto;\"> |\n",
    "| By <a href=\"//commons.wikimedia.org/wiki/File:Mikael_H%C3%A4ggstr%C3%B6m_at_pathology_in_2019_(crop).jpg\" class=\"mw-file-description\"></a><a href=\"//commons.wikimedia.org/wiki/User:Mikael_H%C3%A4ggstr%C3%B6m\" title=\"User:Mikael Häggström\">Mikael Häggström</a>, <a href=\"https://en.wikipedia.org/wiki/Medical_Doctor\" class=\"extiw\" title=\"en:Medical Doctor\">M.D.</a> <a href=\"//commons.wikimedia.org/wiki/Mikael_H%C3%A4ggstr%C3%B6m\" class=\"mw-redirect\" title=\"Mikael Häggström\">Author info</a>- <a href=\"//commons.wikimedia.org/wiki/User:Mikael_H%C3%A4ggstr%C3%B6m#Reusing_images\" title=\"User:Mikael Häggström\">Reusing images</a>- Conflicts of interest:&nbsp; None<a href=\"//commons.wikimedia.org/wiki/User:Mikael_H%C3%A4ggstr%C3%B6m\" title=\"User:Mikael Häggström\">Mikael Häggström</a>, <a href=\"https://en.wikipedia.org/wiki/Medical_Doctor\" class=\"extiw\" title=\"en:Medical Doctor\">M.D.</a> - <span class=\"int-own-work\" lang=\"en\">Own work</span>, <a href=\"http://creativecommons.org/publicdomain/zero/1.0/deed.en\" title=\"Creative Commons Zero, Public Domain Dedication\">CC0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=138411803\">Link</a> | By <a href=\"//commons.wikimedia.org/wiki/File:Mikael_H%C3%A4ggstr%C3%B6m_at_pathology_in_2019_(crop).jpg\" class=\"mw-file-description\"></a><a href=\"//commons.wikimedia.org/wiki/User:Mikael_H%C3%A4ggstr%C3%B6m\" title=\"User:Mikael Häggström\">Mikael Häggström</a>, <a href=\"https://en.wikipedia.org/wiki/Medical_Doctor\" class=\"extiw\" title=\"en:Medical Doctor\">M.D.</a> <a href=\"//commons.wikimedia.org/wiki/Mikael_H%C3%A4ggstr%C3%B6m\" class=\"mw-redirect\" title=\"Mikael Häggström\">Author info</a>- <a href=\"//commons.wikimedia.org/wiki/User:Mikael_H%C3%A4ggstr%C3%B6m#Reusing_images\" title=\"User:Mikael Häggström\">Reusing images</a>- Conflicts of interest:&nbsp; None<a href=\"//commons.wikimedia.org/wiki/User:Mikael_H%C3%A4ggstr%C3%B6m\" title=\"User:Mikael Häggström\">Mikael Häggström</a>, <a href=\"https://en.wikipedia.org/wiki/Medical_Doctor\" class=\"extiw\" title=\"en:Medical Doctor\">M.D.</a> - <span class=\"int-own-work\" lang=\"en\">Own work</span>Reference: Ferrie, C., &amp; Kaiser, S. (2019) Neural Networks for Babies, Sourcebooks <span lang=\"en\" dir=\"ltr\"><a href=\"https://en.wikipedia.org/wiki/ISBN\" class=\"extiw\" title=\"en:ISBN\"><span lang=\"en\" dir=\"ltr\">ISBN</span></a></span>: <a href=\"//commons.wikimedia.org/wiki/Special:BookSources/1492671207\" title=\"Special:BookSources/1492671207\">1492671207</a>., <a href=\"http://creativecommons.org/publicdomain/zero/1.0/deed.en\" title=\"Creative Commons Zero, Public Domain Dedication\">CC0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=137892223\">Link</a> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Complex Neural Network Architecture\n",
    "Networks with many neurons and many layers can model highly complex relationships\n",
    "\n",
    "![Complex artificial neural network](https://teaching.bowyer.io/SDSAI/5/img/Illustrations-SDSAI-05_Complex-ANN.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Input Layer\n",
    "*   **Function:** Takes the raw data and sends it into the network without any transformation or activation\n",
    "*   **Number:** The number of neurons in the input layer is the number of features you have\n",
    "*   **Connection:** Each input neuron is connected to each neuron in the first hidden layer\n",
    "*   **Example:** Each input neuron would be one of the features you observed per patient\n",
    "\n",
    "![Complex artificial neural network](https://teaching.bowyer.io/SDSAI/5/img/Illustrations-SDSAI-05_Complex-ANN.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hidden Layer(s)\n",
    "*   **Function:** Allow for the translation of the input data into increasingly abstract representations that model them\n",
    "*   **Number of neurons:** The number of neurons per layer is a model parameter. More neurons can model more complex relationships.\n",
    "*   **Number of layers:** The number of layers is a model parameter. More layers can model deeper level features.\n",
    "*   **Connection:** Each neuron is (**typically**) connected to each neuron in the next layer\n",
    "*   **Example:** The first layer could learn to derive BMI from height and weight\n",
    "\n",
    "![Complex artificial neural network](https://teaching.bowyer.io/SDSAI/5/img/Illustrations-SDSAI-05_Complex-ANN.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Output Layer\n",
    "*   **Function:** Takes the abstracted data representation from the final hidden layer and produces the final prediction/classification\n",
    "*   **Number (regression):** A single output neuron combines the network data into a single value\n",
    "*   **Number (binary classification):** A single output neuron with a value between 0 and 1\n",
    "*   **Number (multi-classification):** One output neuron per output class\n",
    "*   **Example:** For a mortality prediction the output layer would have one neuron that gives a probability of true/false\n",
    "\n",
    "![Complex artificial neural network](https://teaching.bowyer.io/SDSAI/5/img/Illustrations-SDSAI-05_Complex-ANN.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Softmax\n",
    "*   There is a challenge with multi-classification problems where you want to have a probability value per class ...\n",
    "*   Consider a classifier with three possible outputs (high, medium, and low risk) and your output neurons produce `[2.2, 0.4, 0.1]`, but you want to know the probability of being in each risk category\n",
    "*   Softmax is a function that allows you to combine your output layer values together and produce a probability distribution across the classes such that all sum to 1 (i.e. probabilities)\n",
    "    *   e.g. `[2.2, 0.4, 0.1]` becomes `[0.78, 0.13, 0.10]`\n",
    "*   This function is computationally efficient during training (which we will consider next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "| **Aspect**                 | **Input Layer**                                    | **Hidden Layer(s)**                               | **Output Layer**                                  |\n",
    "|----------------------------|----------------------------------------------------|---------------------------------------------------|---------------------------------------------------|\n",
    "| **Role**                   | Receives and passes input data to the network      | Processes data, learns features and patterns      | Generates the final prediction or output          |\n",
    "| **Data Handling**          | Takes raw input data (e.g., features, images)      | Transforms data through weighted connections      | Produces output suitable for the task (class/probability/value) |\n",
    "| **Activation Function**    | None                                               | Non-linear functions (e.g., ReLU, Tanh, Sigmoid)  | Depends on the problem: Softmax, Sigmoid, Linear  |\n",
    "| **Number of Neurons**      | Equal to the number of input features              | Varies based on network architecture              | Depends on the output type (e.g., 1 for regression, n for n-class classification) |\n",
    "| **Complexity**             | Simple; no learning occurs in this layer           | Complex; learns hierarchical features and patterns| Simple; maps learned features to output space     |\n",
    "| **Learning Role**          | No learning or transformations                     | Learns and extracts meaningful features           | Outputs the final result of the network’s learning|\n",
    "| **Example**                | Each neuron represents a patient feature (e.g., age, heart rate, blood pressure) | Neurons learn interactions between features (e.g., BMI) | Outputs probability of mortality (e.g., risk score or binary prediction) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Network Initialisation\n",
    "*   To start training a neural network on data, you need an initial 'guess' at the weights/biases\n",
    "*   You can start by assigning the values randomly; however, the distribution for should be carefully considered to avoid training instability (see later on)\n",
    "*   Methods such as Xavier (Glorot) or He (Kaiming) initialisation define distributions to sample from to for different activation functions\n",
    "\n",
    "![Complex artificial neural network](https://teaching.bowyer.io/SDSAI/5/img/Illustrations-SDSAI-05_Training-ANN-2.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Forward Propagation\n",
    "*   The next step is to simply use your (semi-randomly initialised) network to make a prediction for your training data\n",
    "*   For example:\n",
    "    *   we have a `2.1` and `1.0` as the two features of the first sample in our training data\n",
    "    *   the neural network output predicts a probability of `0.8`\n",
    "    *   however, the real value should be False (`0.0`)\n",
    "    *   the model is currently poorly trained\n",
    "\n",
    "![Artificial neural network training 3](https://teaching.bowyer.io/SDSAI/5/img/Illustrations-SDSAI-05_Training-ANN-3.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loss Functions\n",
    "*   To train the model, we need a 'loss function'\n",
    "*   Simplistically, this is a measure of how 'bad' the model is at predicting\n",
    "    *   i.e. a loss function of 0 would be correct\n",
    "*   **Regression:** typically use the 'Mean Squared Error' (MSE)\n",
    "*   **Classification:** typically uses the 'Cross-Entropy Loss'\n",
    "*   There are others and you should explore these when you build a model - justify your choice\n",
    "\n",
    "![Artificial neural network training 4](https://teaching.bowyer.io/SDSAI/5/img/Illustrations-SDSAI-05_Training-ANN-4.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How Do We Update the Model to Make it Better?\n",
    "We want the cross-entropy loss to as low as possible, which means we want the output layer to predict the same as the training data ...\n",
    "\n",
    "![Artificial neural network training 4](https://teaching.bowyer.io/SDSAI/5/img/Illustrations-SDSAI-05_Training-ANN-4.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Back Propagation - Conceptually\n",
    "*   The idea is to 'nudge' the weights in the network so they slightly reduce the loss at each iteration\n",
    "*   We step backwards through the neural network, at each layer:\n",
    "    *   Adjust the weights and bias so that the output moves in the direction that minimises the loss\n",
    "    *   Adjust the weights such that larger changes are applied to greater improvements\n",
    "    *   Propogate the required changes (errors) in the previous layer's outputs\n",
    "*   Once we reach the input layer, the neural network should be slightly better at the trained sample\n",
    "*   Repeating this process over and over causes the network's parameters to converge on a trained configuration\n",
    "\n",
    "![Artificial neural network training 4](https://teaching.bowyer.io/SDSAI/5/img/Illustrations-SDSAI-05_Training-ANN-4.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Back Propagation - Computationally\n",
    "*   In practice, you want to minimise the loss for all your training samples at once\n",
    "    *   So you combine them into a single loss (or cost) function\n",
    "*   Python performs back propagation by computing the gradient of the cost function in the model parameters and adjusting them appropriately\n",
    "*   How big a 'step' the solver takes at a time is controlled by the learning rate\n",
    "*   This is a common computational approach called 'Gradient Descent'\n",
    "\n",
    "<video width=\"640\" height=\"360\" controls loop autoplay muted>\n",
    "  <source src=\"https://upload.wikimedia.org/wikipedia/commons/4/4c/Gradient_Descent_in_2D.webm\" type=\"video/webm\">\n",
    "  Your browser does not support the video tag.\n",
    "</video>\n",
    "\n",
    "By Gpeyre, CC-SA 4.0 https://commons.wikimedia.org/wiki/File:Gradient_Descent_in_2D.webm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training Challenges\n",
    "There are some challenges in training neural networks ...\n",
    "\n",
    "*   **Vanishing Gradients:** learning can become very slow or stop in early layers due to the very shallow gradients of the sigmoid and tanh activation functions\n",
    "*   **Exploding Gradients:** learning becomes unstable due to large gradients resulting from poor initialisation\n",
    "*   **Dead ReLU Units:** learning stops because ReLU neurons get stuck in the 0 region with no gradient to recover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural Network Classifier in `scikit-learn`\n",
    "*   In `scikit-learn` the typical neural network is the `MLPClassifier`\n",
    "*   This is a Multi-Layer Perceptron (a simple feedforward neural network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise - Mortality Prediction\n",
    "Take your mortality prediction models from last week's tutorial and try to use a neural network classifier, validate and compare your performance to the linear classifier.\n",
    "\n",
    "Explore different model parameters:\n",
    "*   What does increasing the number/size of layers achieve?\n",
    "*   Which activation functions work?\n",
    "*   What happens when you increase/decrease the learning rate?\n",
    "\n",
    "What configuration gives you the best performance?\n",
    "\n",
    "What do you think is limiting your ability to get better performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simple Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[12550    55]\n",
      " [ 1508   109]]\n",
      "Accuracy: 0.890099845310083\n",
      "f1-score: 0.12240314430095452\n",
      "ROC AUC:  0.5315227169083349\n",
      "N:                              71110\n",
      "Cross-Validation Accuracy Mean: 0.8869076079313739\n",
      "Cross-Validation F1 Mean:       0.10674687476466245\n",
      "Cross-Validation ROC AUC Mean:  0.7005425104687292\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_auc_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Prepare our data\n",
    "data = df_day1_vitalsign.dropna(subset=['admission_age', 'heart_rate_mean', 'sbp_mean', 'glucose_mean', 'mortality'])\n",
    "X = data[['admission_age', 'heart_rate_mean', 'sbp_mean', 'glucose_mean']]\n",
    "Y = data['mortality']\n",
    "\n",
    "# Create the Neural network with 20 neurons in the hidden layer\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(20),\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# Train Test Split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Test the model\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(Y_test, Y_pred)}\")\n",
    "print(f\"Accuracy: {accuracy_score(Y_test, Y_pred)}\")\n",
    "print(f\"f1-score: {f1_score(Y_test, Y_pred)}\")\n",
    "print(f\"ROC AUC:  {roc_auc_score(Y_test, Y_pred)}\")\n",
    "\n",
    "# Cross validate to assess the balanced performance\n",
    "nn_scores = cross_validate(model, X, Y, cv=5, scoring=['f1','accuracy','precision','recall','roc_auc'])\n",
    "\n",
    "print(f'N:                              {len(Y)}')\n",
    "print(f'Cross-Validation Accuracy Mean: {nn_scores[\"test_accuracy\"].mean()}')\n",
    "print(f'Cross-Validation F1 Mean:       {nn_scores[\"test_f1\"].mean()}')\n",
    "print(f'Cross-Validation ROC AUC Mean:  {nn_scores[\"test_roc_auc\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Neural Networks\n",
    "Deep neural networks are the most active area of ML research, here we will introduce the concept and give a few examples of approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "*   Deep learning is the process of using neural networks to model highly complex relationships between data\n",
    "*   Simplistically, these are neural networks with many hidden layers (maybe 10s or even 100s)\n",
    "*   The idea is that more layers/neurons can abstract concepts to a much greater degree\n",
    "*   Modelling these complex relationships requires **LARGE** datasets\n",
    "*   Deep neural networks often involve more complicated neuron arrangements (e.g. RNN, CNN, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deep Neural Network Examples\n",
    "\n",
    "### DenseNet-264\n",
    "*   Convolutional Neural Network architecture\n",
    "*   264 layers\n",
    "*   33 million parameters\n",
    "\n",
    "### AlphaFold from DeepMind (allegedly...)\n",
    "*   Hybrid architecture\n",
    "*   Dozens of layers\n",
    "*   ~100 million parameters\n",
    "*   Trained with ~1,000 TPUs for several months\n",
    "\n",
    "### GPT-4 from OpenAI (allegedly...)\n",
    "*   Transformer architecture\n",
    "*   120 layers\n",
    "*   1.8 trillion parameters\n",
    "*   Trained with 1,000s of GPUs over 90-100 days (cost of $63M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Advantages\n",
    "*   **High Performance:** these models are repeatedly shown to perform well on complex problems\n",
    "*   **Model Abstraction/Translation:** the high degree of abstraction in hidden layers allows them to be applied/translated to related tasks\n",
    "*   **Feature Engineering:** the model's ability to abstract the input data means it can find/engineer features itself\n",
    "*   **Utilise Large and High-Dimensional Data:** the models are capable of learning detail from massive amounts of data with thousands of dimensions\n",
    "*   **Flexibility:** the architecture can be configured to specialise on several types of data/problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Disadvantages\n",
    "*   **Data Requirements:** massive datasets are required for training to learn complex relationships\n",
    "*   **Computational Cost:** training can take a long time and require expensive resources\n",
    "*   **High Parameterisation:** models have many parameters that need setting to perform optimally\n",
    "*   **Overfitting:** massive numbers of parameters can end up overfitting the data\n",
    "*   **Interpretability:** complex architectures and large numbers of parameters make the models almost impossible to interpret/explain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neural Networks for Computer Vision\n",
    "*   Neural networks were crucial in the development of computer vision, e.g.:\n",
    "    *   Image classification\n",
    "    *   Object detection\n",
    "    *   Image generation\n",
    "    *   etc.\n",
    "*   To train a neural network on 'unstructured' data such as a medical image you need to 'flatten' the data\n",
    "*   Each pixel in the image becomes an individual feature, and is passed to the input layer of the neural network\n",
    "\n",
    "![Image analysis NN](https://teaching.bowyer.io/SDSAI/5/img/Illustrations-SDSAI-05_Image-ANN.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convolutional Neural Networks (CNN)\n",
    "*   Special neurons are used in the convolution layers where a small filter is applied to the data\n",
    "*   These filters identify (initially) simple elements of the image (e.g. edges)\n",
    "*   By layering these filters, they can learn increasingly complex patterns (e.g. edges, windows, houses)\n",
    "*   The structure of these filters are learnt during training\n",
    "\n",
    "![Typical CNN](https://upload.wikimedia.org/wikipedia/commons/6/63/Typical_cnn.png)\n",
    "\n",
    "By <a href=\"//commons.wikimedia.org/w/index.php?title=User:Aphex34&amp;action=edit&amp;redlink=1\" class=\"new\" title=\"User:Aphex34 (page does not exist)\">Aphex34</a> - <span class=\"int-own-work\" lang=\"en\">Own work</span>, <a href=\"https://creativecommons.org/licenses/by-sa/4.0\" title=\"Creative Commons Attribution-Share Alike 4.0\">CC BY-SA 4.0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=45679374\">Link</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Do you think these neural networks are capable of giving predictions that remember previous inputs?\n",
    "\n",
    "For example, imagine you wanted to build a model to predict some adverse event during surgery, based on continuous monitoring data. You need your model to constantly be running on the latest observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recurrent Neural Networks\n",
    "*   So far, we have looked at 'feed forward' networks - i.e. the data is fed forward from the input to output layer\n",
    "    *   These are 'stateless' - i.e. cannot remember anything between inputs\n",
    "    *   It does not have to be this way\n",
    "*   Recurrent Neural Networks (RNN) are neural networks with memory\n",
    "    *   Long Short-Term Memory (LSTM) are the most popular RNN architecture that can 'remember' values over a long period and then 'forget' them when necessary\n",
    "\n",
    "![Recurrent Neural Network](https://teaching.bowyer.io/SDSAI/5/img/Illustrations-SDSAI-05_RNN.svg)\n",
    "\n",
    "*   RNNs were commonly used for timeseries data; however, have fallen out of fashion with the popularity of 'transformers'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transformers\n",
    "*   Transformers do not worry about remembering the state between inputs - they take the whole history as an input each time\n",
    "*   They have revolutionised NLP and other sequential (unstructured) data modelling tasks\n",
    "*   **Key Components**\n",
    "    *   **Self-attention:** allows the model to learn the importance of relationships between input tokens (i.e. surgery event -> infection event)\n",
    "    *   **Positional encoding:** allows the model to understand the sequential order of inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Reliability, Reproducibility, and Optimality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## In the last tutorial, what did you find with the SVM, KNN and decision tree methods when trying to get good performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hyperparameter Tuning\n",
    "*   As models become more powerful, they tend to have increasing numbers of parameters\n",
    "*   For example:\n",
    "    *   Number of neighbours in KNN\n",
    "    *   Depth of a decision tree\n",
    "    *   Layers, neurons, activation functions, etc for neural networks\n",
    "*   We call these **hyperparameters**\n",
    "*   You have seen that variation in these parameters can effect model performance enormously\n",
    "\n",
    "**How do you think we can ensure we have the best configuration for our model's hyperparameters?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Grid Search\n",
    "Involves systematically searching combinations of hyperparameters to find the best score\n",
    "*   Approach guarantees a 'reasonable' proximity to the optimal values\n",
    "*   `from sklearn.model_selection import GridSearchCV`\n",
    "\n",
    "![Grid search hyperparameter optimisation](https://upload.wikimedia.org/wikipedia/commons/b/b6/Hyperparameter_Optimization_using_Grid_Search.svg)\n",
    "\n",
    "By <a href=\"//commons.wikimedia.org/w/index.php?title=User:Alexander_Elvers&amp;action=edit&amp;redlink=1\" class=\"new\" title=\"User:Alexander Elvers (page does not exist)\">Alexander Elvers</a> - <span class=\"int-own-work\" lang=\"en\">Own work</span>, <a href=\"https://creativecommons.org/licenses/by-sa/4.0\" title=\"Creative Commons Attribution-Share Alike 4.0\">CC BY-SA 4.0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=84255403\">Link</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Random Search\n",
    "Involves randomly saerching combinations of hyperparameters to find the best score\n",
    "*   Explores the continuous value space more efficiently than the grid search\n",
    "*   `from sklearn.model_selection import RandomizedSearchCV`\n",
    "\n",
    "![Random search hyperparameter optimisation](https://upload.wikimedia.org/wikipedia/commons/7/74/Hyperparameter_Optimization_using_Random_Search.svg)\n",
    "\n",
    "By <a href=\"//commons.wikimedia.org/w/index.php?title=User:Alexander_Elvers&amp;action=edit&amp;redlink=1\" class=\"new\" title=\"User:Alexander Elvers (page does not exist)\">Alexander Elvers</a> - <span class=\"int-own-work\" lang=\"en\">Own work</span>, <a href=\"https://creativecommons.org/licenses/by-sa/4.0\" title=\"Creative Commons Attribution-Share Alike 4.0\">CC BY-SA 4.0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=84255404\">Link</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayesian Optimisation\n",
    "Involves using an optimisation approach to search in areas where it expects the performance to be better\n",
    "*   Typically finds optima more quickly than random search\n",
    "*   `from skopt import BayesSearchCV`\n",
    "\n",
    "![Bayesian Optimisation hyperparameter optimisation](https://upload.wikimedia.org/wikipedia/commons/3/3c/Hyperparameter_Optimization_using_Tree-Structured_Parzen_Estimators.svg)\n",
    "\n",
    "By <a href=\"//commons.wikimedia.org/w/index.php?title=User:Alexander_Elvers&amp;action=edit&amp;redlink=1\" class=\"new\" title=\"User:Alexander Elvers (page does not exist)\">Alexander Elvers</a> - <span class=\"int-own-work\" lang=\"en\">Own work</span>, <a href=\"https://creativecommons.org/licenses/by-sa/4.0\" title=\"Creative Commons Attribution-Share Alike 4.0\">CC BY-SA 4.0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=84255405\">Link</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Grid Search in `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:      0.7274227972755576\n",
      "Best Parameters: {'activation': 'logistic', 'hidden_layer_sizes': 40}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "data = df_day1_vitalsign.dropna(subset=['admission_age', 'heart_rate_mean', 'sbp_mean', 'glucose_mean', 'mortality'])\n",
    "X = data[['admission_age', 'heart_rate_mean', 'sbp_mean', 'glucose_mean']]\n",
    "Y = data['mortality']\n",
    "\n",
    "# Create the initial model\n",
    "model = MLPClassifier(random_state=1)\n",
    "\n",
    "# Define the grid search\n",
    "grid_search = GridSearchCV(\n",
    "    model,\n",
    "    param_grid={\n",
    "        'hidden_layer_sizes': range(5,45,5),\n",
    "        'activation': ['relu', 'logistic', 'tanh']\n",
    "    },\n",
    "    scoring='roc_auc'\n",
    ")\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X, Y)\n",
    "\n",
    "# Get the best score and best parameters\n",
    "print(f\"Best Score:      {grid_search.best_score_}\")\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model Sensitivity/Stability\n",
    "*   You can use the hyperparameter optimisation to assess the sensitivity and stability of a model\n",
    "*   If small changes in parameters lead to large changes in performance, the model is 'sensitive' and maybe overfit\n",
    "*   If large changes in parameters lead to small changes in performance, the model is either already at it's limit, underfit, or suffering from some other issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": [
     "side-by-side"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc_values = grid_search.cv_results_['mean_test_score'][grid_search.cv_results_['param_activation'] == 'logistic']\n",
    "nneuron_values = grid_search.cv_results_['param_hidden_layer_sizes'][grid_search.cv_results_['param_activation'] == 'logistic']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(nneuron_values, auc_values)\n",
    "plt.xlabel(\"Neurons in Layer\")\n",
    "plt.ylabel(\"ROC AUC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wrap Up\n",
    "*   You now have lots of tools to address supervised machine learning problems; however, experience and reading up on the nuances of each method is the difference between using them well\n",
    "*   REMEMBER... if your model does not have the key features of the system/disease/procedure/etc. you are trying to predict, no matter how complex you make your model or how many samples you collect, it will never improve its performance\n",
    "\n",
    "![](https://assets.cureus.com/uploads/figure/file/292667/article_river_6a398820513311ecb45235ba7f0fde7e-LRvsNN_plot4.png)\n",
    "\n",
    "Issitt R W, Cortina-Borja M, Bryant W, et al. (February 21, 2022) Classification Performance of Neural Networks Versus Logistic Regression Models: Evidence From Healthcare Practice. Cureus 14(2): e22443. doi:10.7759/cureus.2244"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Before Next Session\n",
    "*   Review background on neural networks\n",
    "*   Complete the tutorial exercises\n",
    "\n",
    "### New Material\n",
    "*   Tutorial on CNN for image classification - https://www.tensorflow.org/tutorials/images/cnn\n",
    "*   OPTIONAL Very detailed description of the DeepMind AlphaFold 3, so you can understand the complexity possible in Deep Neural Networks - https://elanapearl.github.io/blog/2024/the-illustrated-alphafold/\n",
    "\n",
    "### Consolidation Reading\n",
    "*   Excellent interactive Google tutorial that lets you visually explore neural networks - https://developers.google.com/machine-learning/crash-course/neural-networks "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
