{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://teaching.bowyer.io/SDSAI/0/img/IMPERIAL_logo_RGB_Blue_2024.svg\" alt=\"Imperial Logo\" width=\"500\"/><br /><br />\n",
    "\n",
    "Ensemble Methods and Unsupervised Learning\n",
    "==============\n",
    "### SURG70098 - Surgical Data Science and AI\n",
    "### Stuart Bowyer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Intended Learning Outcomes\n",
    "1.  ???\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MIMIC Dataset\n",
    "The following code will load the datasets used in this lecture notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "%pip install pandas_gbq\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_gbq\n",
    "\n",
    "project_id = 'mimic-project-439314'  # @param {type:\"string\"}\n",
    "\n",
    "df_day1_vitalsign = pandas_gbq.read_gbq(\"\"\"\n",
    "  SELECT\n",
    "    *,\n",
    "    (dod IS NOT NULL) AND (dod <= dischtime) AS mortality,\n",
    "    weight / POWER(height/100, 2) > 30 AS obese\n",
    "  FROM `physionet-data.mimiciv_derived.first_day_vitalsign`\n",
    "  LEFT JOIN (\n",
    "    SELECT\n",
    "      subject_id,\n",
    "      stay_id,\n",
    "      gender,\n",
    "      race,\n",
    "      dischtime,\n",
    "      admission_age,\n",
    "      dod\n",
    "    FROM\n",
    "      `physionet-data.mimiciv_derived.icustay_detail`\n",
    "  )\n",
    "  USING(subject_id, stay_id)\n",
    "  LEFT JOIN (\n",
    "    SELECT\n",
    "      stay_id,\n",
    "      AVG(weight) as weight\n",
    "    FROM\n",
    "      `physionet-data.mimiciv_derived.weight_durations`\n",
    "    GROUP BY\n",
    "      stay_id\n",
    "  )\n",
    "  USING(stay_id)\n",
    "  LEFT JOIN (\n",
    "    SELECT\n",
    "      stay_id,\n",
    "      CAST(AVG(height) AS FLOAT64) AS height\n",
    "    FROM\n",
    "      `physionet-data.mimiciv_derived.height`\n",
    "    GROUP BY\n",
    "      stay_id\n",
    "  )\n",
    "  USING(stay_id)\n",
    "  WHERE heart_rate_mean IS NOT NULL\n",
    "\"\"\", project_id=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to Ensemble Methods\n",
    "*   You probably have noticed that different models have different advantages and disadvantages\n",
    "*   i.e. sometimes they work well, others they do not\n",
    "*   Ensemble methods combine models together to improve overall performance by ...\n",
    "    *   Improving accuracy\n",
    "    *   Improving stability\n",
    "    *   Reducing error\n",
    "\n",
    "**How would you combine models together to optimise their group performance?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bootstrap Aggregating (Bagging)\n",
    "*   Builds multiple parallel models independently using random (possibly overlapping) subsets of the data and combines their predictions\n",
    "*   Aim is to reduce overfitting by varying the patterns each model is trained on and reducing variance by combining outputs\n",
    "*   Very commonly used with decision trees to create **random forests**\n",
    "    *   `from sklearn.ensemble import RandomForestClassifier`\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/7/76/Random_Forest_Diagram_Extra_Wide.png)\n",
    "\n",
    "By <a href=\"//commons.wikimedia.org/w/index.php?title=User:CollaborativeGeneticist&amp;action=edit&amp;redlink=1\" class=\"new\" title=\"User:CollaborativeGeneticist (page does not exist)\">CollaborativeGeneticist</a> - <span class=\"int-own-work\" lang=\"en\">Own work</span>, <a href=\"https://creativecommons.org/licenses/by-sa/4.0\" title=\"Creative Commons Attribution-Share Alike 4.0\">CC BY-SA 4.0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=113209159\">Link</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Boosting\n",
    "*   Builds sequential models that try to correct the errors of the predecessor\n",
    "*   Aim is to reduce underfitting (due to weak models) by focusing models on the errors of other models\n",
    "*   Very commonly used with deision trees to create **gradient boosted trees**\n",
    "    *   `from sklearn.ensemble import GradientBoostingClassifier`\n",
    "    *   popular alternative implementation is 'XGBoost'\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/b5/Ensemble_Boosting.svg\" alt=\"Description of Image\" style=\"height: 400px; display: block; margin: 0 auto;\">\n",
    "\n",
    "By <a href=\"//commons.wikimedia.org/wiki/User:Sirakorn\" title=\"User:Sirakorn\">Sirakorn</a> - <span class=\"int-own-work\" lang=\"en\">Own work</span>, <a href=\"https://creativecommons.org/licenses/by-sa/4.0\" title=\"Creative Commons Attribution-Share Alike 4.0\">CC BY-SA 4.0</a>, <a href=\"https://commons.wikimedia.org/w/index.php?curid=85888769\">Link</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Class Imbalance\n",
    "*   One of the common issues you will face is class imbalances\n",
    "*   i.e. when one of your predicted classes is much more/less common than the others\n",
    "*   For example, in the MIMIC dataset ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mortality\n",
       "False    0.883693\n",
       "True     0.116307\n",
       "Name: proportion, dtype: Float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_day1_vitalsign.mortality.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   This imbalance can cause training bias and poor performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Can you suggest how to address the class imbalance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Oversampling\n",
    "*   Involves creating new observations in the minority class by ...\n",
    "*   **Random oversampling:** randomly duplicating entries from the minority class\n",
    "*   **Synthetic Minority Over-sampling Technique (SMOTE):** generating new synthetic samples in the minority class by interpolating between existing observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Undersampling\n",
    "*   Involves dropping observations in the majority class by ...\n",
    "*   **Random undersampling:** randomly removing entries from the majority class\n",
    "*   **Tomek links:** removes entries from the majority class that are close to the minority class (i.e. suspected noise)\n",
    "*   **NearMiss:** removes entries from the majority class that are far from the minority class (i.e. easy classifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using `imbalanced-learn`\n",
    "*   Python has a package (parallelling `scikit-learn`) for addressing imbalanced datasets\n",
    "    *    [Oversampling methods](https://imbalanced-learn.org/stable/references/over_sampling.html)\n",
    "    *    [Undersampling methods](https://imbalanced-learn.org/stable/references/over_sampling.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous value counts:  [63076, 8034]\n",
      "Resampled value counts: [63076, 63076]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "data = df_day1_vitalsign.dropna(subset=['admission_age', 'heart_rate_mean', 'sbp_mean', 'glucose_mean', 'mortality'])\n",
    "X = data[['admission_age', 'heart_rate_mean', 'sbp_mean', 'glucose_mean']]\n",
    "Y = data['mortality']\n",
    "\n",
    "# Create the random oversampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "\n",
    "# Apply it to our dataset\n",
    "X_res, Y_res = ros.fit_resample(X, Y)\n",
    "\n",
    "print(\"Previous value counts: \", Y.value_counts().to_list())\n",
    "print(\"Resampled value counts:\", Y_res.value_counts().to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 6.1 - Supervised Learning Challenge\n",
    "Use the [Wisconsin Breast Cancer Database](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic) to build the most high performance classifier for predicting tumour malignancy from breast mass features.\n",
    "\n",
    "98% accuracy is possible\n",
    "\n",
    "There are instructions on importing the dataset to Python on the above page.\n",
    "\n",
    "I suggest starting with logistic regression on a subset of features, but you should expect to build up the model complexity and number of features.\n",
    "\n",
    "You will probably want to use most of the techniques you have learnt in the past two/three lectures:\n",
    "*   Some basic EDA of this new dataset\n",
    "*   Ensuring the data are fully prepared\n",
    "*   Exploring different classification methods\n",
    "*   Searching for optimal parameters\n",
    "*   Addressing class imbalances\n",
    "*   Testing other performance improvements (ensemble methods)\n",
    "*   Using effective model validation\n",
    "\n",
    "**Before you start, what metric/s should we use?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wrap Up\n",
    "*   ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Before Next Session\n",
    "*   Review random forest and gradient boosting methods\n",
    "\n",
    "### New Material\n",
    "*   Random Forest - https://williamkoehrsen.medium.com/random-forest-simple-explanation-377895a60d2d\n",
    "*   xgboost Introduction - https://xgboost.readthedocs.io/en/stable/tutorials/model.html\n",
    "\n",
    "### Consolidation Reading\n",
    "*   ???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
