{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://teaching.bowyer.io/SDSAI/0/img/IMPERIAL_logo_RGB_Blue_2024.svg\" alt=\"Imperial Logo\" width=\"500\"/><br /><br />\n",
    "\n",
    "Machine Learning Foundations and Data Preparation\n",
    "==============\n",
    "### SURG70098 - Surgical Data Science and AI\n",
    "### Stuart Bowyer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Intended Learning Outcomes\n",
    "1.  Describe what is meant by machine learning and the fundamental aspects of machine learning methods \n",
    "1.  Perform exploratory data analyses (EDA) of given datasets to understand how they can be used for machine learning\n",
    "1.  Prepare datasets for use in machine learning by cleaning, transforming, and integrating them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Session Outline\n",
    "1.  [Machine Learning Foundations](#pandas)\n",
    "1.  [Exploratory Data Analysis](#pandas)\n",
    "1.  [Data Cleaning](#pandas)\n",
    "1.  [Data Transformation](#pandas)\n",
    "1.  [Data Integration](#pandas)\n",
    "1.  [Wrap Up](#wrap_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Connecting to MIMIC\n",
    "*   We will connect to the MIMIC databases using the `pandas-gbq` library\n",
    "*   You should have already got access to MIMIC and setup a Google Cloud project before the session\n",
    "*   To make the examples in this session work:\n",
    "    *   Go to you [BigQuery project](https://console.cloud.google.com/bigquery) to get your `project_id`\n",
    "    *   Input your `project_id` below, in my case it is `mimic-project-439312`\n",
    "    *   Run this code block and it will store the datasets in your environment for use later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "%pip install pandas_gbq\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_gbq\n",
    "\n",
    "project_id = \"mimic-project-439314\"  # <--- INPUT YOUR PROJECT ID HERE\n",
    "\n",
    "df_ventilator_setting = pandas_gbq.read_gbq(\"\"\"\n",
    "  SELECT *\n",
    "  FROM `physionet-data.mimiciv_derived.ventilator_setting`\n",
    "  WHERE ventilator_type IS NOT NULL\n",
    "  LIMIT 1000\n",
    "\"\"\", project_id=project_id)\n",
    "\n",
    "df_vitalsign = pandas_gbq.read_gbq(\"\"\"\n",
    "  SELECT *\n",
    "  FROM `physionet-data.mimiciv_derived.vitalsign`\n",
    "  LIMIT 10000\n",
    "\"\"\", project_id=project_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning Foundations\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Cleaning\n",
    "Data cleaning is concerned with taking messy real-world data and making is appropriate for use in a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What Makes Data 'Messy'\n",
    "Based on what you know about programming with data, what issues might there with using the following data to build a model?\n",
    "\n",
    "| PatientID | Name         | Age   | Weight       | Height      | BloodPressure | Temp     | Diagnosis       | Gender  | AppointmentDate  |\n",
    "|-----------|--------------|-------|--------------|-------------|---------------|----------|-----------------|---------|------------------|\n",
    "| 101       | John         | 45    | 180 lbs      | 6'2\"        | 120/80        | 98.6 F   | Hypertension    | M       | 2024-09-15       |\n",
    "| 102       | Jane         |       | 70kg         | 165 cm      | 130/85        | 36.5 C   | Diabetes        | Female  | 15th Sep 2024    |\n",
    "| 103       | Mike         | 53    | 250 lbs      | 72 in       | 140/90        | 100 F    | Hypertension    | M       | 2024-09-14       |\n",
    "| 104       | Anna         | 401   | 50.5 kgs     | 5'4\"        |               | 37 C     | Asthma          | F       | 09/16/2024       |\n",
    "| 105       | Emily        | 60    | 130          | 160cm       |               |          | None            | Female  | 2024-09-13       |\n",
    "| 106       | Chris        | -12   | 80kg         |             | 120/75        | 99.1 F   | Asthma          | Male    | 2024-09-12       |\n",
    "| 107       | Sarah        | 40    | 165.3        | 5.5 ft      | 115/75        |          | Hypertension    | F       | September 14, 24 |\n",
    "| 108       | Bob          | 67    | 200 lbs      |             |               |          | Heart Disease   | Male    | 2024/09/15       |\n",
    "| 109       | Laura        | 32    | 140 lbs      | 1.70m       | 120/80        | 99F      | Hypertension    | Female  | 2024-09-14       |\n",
    "| 110       | David        | 75    | 90kg         | 180 cm      | 110/70        | 37.5C    | None            | M       | 9/15/24          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some Answers...\n",
    "*   Units are inconsistent within the columns\n",
    "*   Many missing values\n",
    "*   Date formatting is inconsistent\n",
    "*   Outliers (obvious in age)\n",
    "*   Categorisations are inconsistent\n",
    "\n",
    "| PatientID | Name         | Age   | Weight       | Height      | BloodPressure | Temp     | Diagnosis       | Gender  | AppointmentDate  |\n",
    "|-----------|--------------|-------|--------------|-------------|---------------|----------|-----------------|---------|------------------|\n",
    "| 101       | John         | 45    | 180 lbs      | 6'2\"        | 120/80        | 98.6 F   | Hypertension    | M       | 2024-09-15       |\n",
    "| 102       | Jane         |       | 70kg         | 165 cm      | 130/85        | 36.5 C   | Diabetes        | Female  | 15th Sep 2024    |\n",
    "| 103       | Mike         | 53    | 250 lbs      | 72 in       | 140/90        | 100 F    | Hypertension    | M       | 2024-09-14       |\n",
    "| 104       | Anna         | 401   | 50.5 kgs     | 5'4\"        |               | 37 C     | Asthma          | F       | 09/16/2024       |\n",
    "| 105       | Emily        | 60    | 130          | 160cm       |               |          | None            | Female  | 2024-09-13       |\n",
    "| 106       | Chris        | -12   | 80kg         |             | 120/75        | 99.1 F   | Asthma          | Male    | 2024-09-12       |\n",
    "| 107       | Sarah        | 40    | 165.3        | 5.5 ft      | 115/75        |          | Hypertension    | F       | September 14, 24 |\n",
    "| 108       | Bob          | 67    | 200 lbs      |             |               |          | Heart Disease   | Male    | 2024/09/15       |\n",
    "| 109       | Laura        | 32    | 140 lbs      | 1.70m       | 120/80        | 99F      | Hypertension    | Female  | 2024-09-14       |\n",
    "| 110       | David        | 75    | 90kg         | 180 cm      | 110/70        | 37.5C    | None            | M       | 9/15/24          |\n",
    "\n",
    "**What effect do you think these 'issues' will have on a model built from this data?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## \"Garbage In Garbage Out\"\n",
    "\n",
    "<table style='table-layout: fixed; width: 100%; margin-top: 0;'>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>\n",
    "        <img src=\"https://teaching.bowyer.io/SDSAI/3/img/Garbage_in_garbage_out_chatgpt.webp \">\n",
    "      </td>\n",
    "      <td>\n",
    "        <ul>\n",
    "          <li>It will probably be clear that any model you build based on poor quality, messy data will produce poor quality results</li>\n",
    "          <li>'Data Cleaning' is the process of improving your input data by correcting or removing errors and inconsistencies</li>\n",
    "          <li>The following are some examples of key data cleaning methods; however, there is no limit to the type of data issues you can find in your data</li>\n",
    "        </ul>\n",
    "      </td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cleaning Medical Data\n",
    "*   One of the biggest challenges in working with medical data is how 'messy' thay are\n",
    "*   There are no definitive approaches to resolving any of these issues. You will need to use judgement about the:\n",
    "    *   data type,\n",
    "    *   data purpose, and\n",
    "    *   <strong>importantly</strong> clinical context (you have an opportunity here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Missing Data\n",
    "*   Missing data is one of the most common data issues you will find with medical data\n",
    "*   Some common reasons for missing data are:\n",
    "    *   Human factors (entry error, non-response, loss)\n",
    "    *   Systemic factors (changing practice/guidelines, limited machine output)\n",
    "    *   Availability (patient opt-out, research approvals, linkage, cost-of-acquisition)\n",
    "\n",
    "❓ **Can you suggest how we might resolve missing data?**\n",
    "\n",
    "\n",
    "| PatientID | Name         | Age   | Weight       | Height      | BloodPressure | Temp     | Diagnosis       | Gender  | AppointmentDate  |\n",
    "|-----------|--------------|-------|--------------|-------------|---------------|----------|-----------------|---------|------------------|\n",
    "| 102       | Jane         |       | 70kg         | 165 cm      | 130/85        | 36.5 C   | Diabetes        | Female  | 15th Sep 2024    |\n",
    "| 104       | Anna         | 401   | 50.5 kgs     | 5'4\"        |               | 37 C     | Asthma          | F       | 09/16/2024       |\n",
    "| 105       | Emily        | 60    | 130          | 160cm       |               |          | None            | Female  | 2024-09-13       |\n",
    "| 106       | Chris        | -12   | 80kg         |             | 120/75        | 99.1 F   | Asthma          | Male    | 2024-09-12       |\n",
    "| 107       | Sarah        | 40    | 165.3        | 5.5 ft      | 115/75        |          | Hypertension    | F       | September 14, 24 |\n",
    "| 108       | Bob          | 67    | 200 lbs      |             |               |          | Heart Disease   | Male    | 2024/09/15       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Identifying Missing Data in pandas\n",
    "*   The standard way to define missing data in pandas is with special symbols `NaN` or `None`\n",
    "*   To find these, there is a pandas method `.isna()`\n",
    "*   There is also the `.notna()` to find which elements are not missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AppointmentDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientID   Name    Age  Weight  Height  BloodPressure   Temp  Diagnosis  \\\n",
       "0      False  False  False   False   False          False  False      False   \n",
       "1      False  False   True   False   False          False  False      False   \n",
       "2      False  False  False   False   False          False  False      False   \n",
       "3      False  False  False   False   False           True  False      False   \n",
       "4      False  False  False   False   False           True   True       True   \n",
       "5      False  False  False   False    True          False  False      False   \n",
       "6      False  False  False   False   False          False   True      False   \n",
       "7      False  False  False   False    True           True   True      False   \n",
       "8      False  False  False   False   False          False  False      False   \n",
       "9      False  False  False   False   False          False  False       True   \n",
       "\n",
       "   Gender  AppointmentDate  \n",
       "0   False            False  \n",
       "1   False            False  \n",
       "2   False            False  \n",
       "3   False            False  \n",
       "4   False            False  \n",
       "5   False            False  \n",
       "6   False            False  \n",
       "7   False            False  \n",
       "8   False            False  \n",
       "9   False            False  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_messy = pd.read_csv(\"https://teaching.bowyer.io/SDSAI/3/data/messy_data.csv\")\n",
    "df_messy.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Counting Missing Data in pandas\n",
    "*   You can then find the number missing, per column, with `.sum()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatientID          0\n",
       "Name               0\n",
       "Age                1\n",
       "Weight             0\n",
       "Height             2\n",
       "BloodPressure      3\n",
       "Temp               3\n",
       "Diagnosis          2\n",
       "Gender             0\n",
       "AppointmentDate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_messy.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dropping Missing Values\n",
    "\n",
    "*   **What:** Exclude the missing data points from your data set\n",
    "*   **How:** If the downstream model permits, you can drop an individual value, otherwise either drop the whole row or column\n",
    "*   **Advantages:** This ensures your analysis/model/etc is based on the most accurate/representative data\n",
    "*   **Disadvantages:** You often need to remove either the whole row or column, which wastes potentially useful data elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Dropping Missing Data in pandas\n",
    "*   To drop a row with missing data, pandas has the `.dropna()` method\n",
    "*   Here you can specify which columns to look for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "df_messy.dropna(subset='BloodPressure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   To drop a column with missing data, you can simply specify the column you wish to drop by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "df_messy.drop('BloodPressure', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Imputation (Replacing Missing Values)\n",
    "*   **What:** Imputation is the process of replacing a missing value with a substitute\n",
    "*   **How:** A range of functions can be used to generate a substitute, from averages to predictive\n",
    "*   **Advantages:** This maximises the available dataset\n",
    "*   **Disadvantages:** Value substitution introduces inaccuracy and uncertainty into the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Imputation Methods\n",
    "##### Constant Value\n",
    "*   Substitute missing values with a fixed constant (based on some context/knowledge)\n",
    "*   ```df['A'].fillna(0)```\n",
    "\n",
    "#### Average Value\n",
    "*   Substutute missing values with the mean value of the non-missing values\n",
    "*   ```df['B'].fillna(df['B'].mean())```\n",
    "*   Could also be the `median()` or `mode()`\n",
    "\n",
    "#### Random (Hot-deck)\n",
    "*   Substitute missing values with a random selection from the available values\n",
    "*   `rnd = pd.Series(np.random.choice(df['C'].dropna(), size=len(df['C'])))`\n",
    "*   `df['C'].fillna(rnd)`\n",
    "\n",
    "#### Regression\n",
    "*   Substitute missing values with a predicted value based on a regression model of other (non-missing) variables\n",
    "\n",
    "#### K-Nearest Neighbours\n",
    "*   Substitute missing values with a predicted value based on a similarity model to other observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Which Method to Use\n",
    "Your choice of which imputation method to use will be based on:\n",
    "*   **Domain knowledge** - what do the data represent, what assumptions are valid\n",
    "*   **Data type** - numerical or categorical\n",
    "*   **Amount of data** - 'small' data will probably limit accuracy of complex approaches\n",
    "*   **Amount missing** - simple subsututions for a high proportion of missing data will introduce bias\n",
    "*   **Downstream model requirements** - are models liable to overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ❓ Quick Exercise\n",
    "Spend the next 5 minutes exploring/addressing the missing data in the `df_ventilator_setting` MIMIC dataset\n",
    "\n",
    "Hints\n",
    "*   Start by identifying how many values per observation (i.e. per column) are missing\n",
    "*   Try using each of the methods we have covered\n",
    "*   Consider the data types, as some are not compatible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Miss-Typed Data\n",
    "*   It is very common for medical data to have been imported as a text string; however, data can often have their type changed\n",
    "*   As a general rule, you want your types to be as simple as possible while maintaining the underlying meaning, i.e.:\n",
    "    *   free text (`str`) → `float` → categorical (`str`) → `int` → `bool`\n",
    "*   You should be careful of using integers to represent categorical data though, as it can imply ordinality that does not exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Type Conversions in pandas\n",
    "*   We covered pandas type conversions extensively in lecture 2\n",
    "*   Types can be easily modified in pandas with the `.astype()` or `pd.to_numeric()` methods\n",
    "*   The `str` methods also allow for conversion of free text inputs to more constrained types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>Systolic</th>\n",
       "      <th>Diastolic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120/80</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130/85</td>\n",
       "      <td>130</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140/90</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>120/75</td>\n",
       "      <td>120</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>115/75</td>\n",
       "      <td>115</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120/80</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>110/70</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  BloodPressure  Systolic  Diastolic\n",
       "0        120/80       120         80\n",
       "1        130/85       130         85\n",
       "2        140/90       140         90\n",
       "5        120/75       120         75\n",
       "6        115/75       115         75\n",
       "8        120/80       120         80\n",
       "9        110/70       110         70"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bp = df_messy[['BloodPressure']].dropna()\n",
    "df_bp[['Systolic','Diastolic']] = df_bp['BloodPressure'] \\\n",
    "    .str.split('/', expand=True) \\\n",
    "    .astype(int)\n",
    "\n",
    "df_bp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inconsistent Data\n",
    "*   Inconsistent data are those where different observations in a given column do not represent the same thing\n",
    "*   A simple example would be measurements with different units (weight in kg or lbs) or taken in different ways (temperature taken internally or peripherally)\n",
    "*   Data should be consistently represented to be useful for modelling and machine learning\n",
    "*   Inconsistent data can be either:\n",
    "    *   Converted to a common consistent format (e.g. converting temperatures to common units `degrees C`)\n",
    "    *   Split into distinct observations (e.g. splitting to `internal_temp` and `peripheral_temp` observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ❓ Quick Exercise\n",
    "Spend the next 5 minutes cleaning types and inconsistencies in the `Temp`, `Gender`, and `BloodGlucose` columns of the toy dataset in `df_messy`\n",
    "\n",
    "Hints\n",
    "*   The conversion from temp in 'F' to 'C' is `(Temp°F − 32) × 5/9 = Temp°C`\n",
    "*   Also look at the `BGMethod` column when considering the `BloodGlucose` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_messy = pd.read_csv(\"https://teaching.bowyer.io/SDSAI/3/data/messy_data.csv\")\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outliers / Invalid Values\n",
    "*   Outliers and invalid values (i.e. impossible/non-physiological values) can be introduced to data by human, acquisition, and transfer errors, as well as exceptional inputs\n",
    "*   You can attempt to define outliers statistically; however, you should always start by considering the context\n",
    "    *   i.e. can the value be negative, or greater than 100%, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Z-score Based Outlier Removal\n",
    "*   If your data are normally (Gaussian) distributed z-scores can be used to identify outliers\n",
    "*   The z-score is a number that represents how many 'standard deviations' a value is from the mean\n",
    "*   Therefore, by setting a limit on the permissible z-score, values 'too far' from average can be removed\n",
    "*   The z-score for a value can be calculated as follows:\n",
    "$$Z = \\frac{X - \\mu}{\\sigma}$$\n",
    "\n",
    "where: $X$ is the value, $\\mu$ is the mean of the column, $\\sigma$ is the standard deviation of the column\n",
    "\n",
    "<img src=\"https://teaching.bowyer.io/SDSAI/3/img/z-score_Illustration.png\" alt=\"z-score illustration\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Z-score Based Outlier Removal Example\n",
    "*   The `temperature` values in the `vitalsign` MIMIC-IV dataset are approximately normal\n",
    "*   With the following, we can eliminate values that are more than 3 standard deviations from the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_temp</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1732.000000</td>\n",
       "      <td>1727.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.895612</td>\n",
       "      <td>36.894823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.459767</td>\n",
       "      <td>0.454323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>35.500000</td>\n",
       "      <td>35.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>36.610000</td>\n",
       "      <td>36.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>36.890000</td>\n",
       "      <td>36.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.170000</td>\n",
       "      <td>37.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>38.280000</td>\n",
       "      <td>38.220000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          old_temp         temp\n",
       "count  1732.000000  1727.000000\n",
       "mean     36.895612    36.894823\n",
       "std       0.459767     0.454323\n",
       "min      35.500000    35.560000\n",
       "25%      36.610000    36.610000\n",
       "50%      36.890000    36.890000\n",
       "75%      37.170000    37.170000\n",
       "max      38.280000    38.220000"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cast to numeric values\n",
    "df_outlier = pd.DataFrame()\n",
    "df_outlier['temp'] = pd.to_numeric(df_vitalsign['temperature'])\n",
    "\n",
    "# Store original temp for comparison at the end\n",
    "df_outlier['old_temp'] = df_outlier['temp']\n",
    "\n",
    "# Compute z-scores using previous equation\n",
    "df_outlier['zscore'] = (df_outlier['temp'] - df_outlier['temp'].mean()) / df_outlier['temp'].std()\n",
    "\n",
    "# Replace extreme values with NaN by using the mask function\n",
    "df_outlier['temp'] = df_outlier['temp'].mask(df_outlier['zscore'].abs() > 3.0)\n",
    "\n",
    "# Check the result\n",
    "df_outlier[['old_temp','temp']].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interquartile Range (IQR) Based Outlier Removal\n",
    "*   When your data are not normally distributed, the IQR can be used as it does not assume a specific distribution\n",
    "*   The IQR is the range between the 25th and 75th percentiles in the data\n",
    "*   Similarly to the z-scores, you can identify outliers by how many times the IQR they are from the first and third quartiles\n",
    "\n",
    "<img src=\"https://teaching.bowyer.io/SDSAI/3/img/IQR_Illustration.png\" alt=\"IQR illustration\" width=\"700\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interquartile Range (IQR) Based Outlier Removal Example\n",
    "*   The `glucose` values in the `vitalsign` MIMIC-IV dataset are non-normal\n",
    "*   With the following, we can eliminate values that are more than 1.5 IQR from IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>old_glucose</th>\n",
       "      <th>glucose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>220.000000</td>\n",
       "      <td>211.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>149.947727</td>\n",
       "      <td>141.481043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>60.651774</td>\n",
       "      <td>43.870883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>108.000000</td>\n",
       "      <td>107.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>136.500000</td>\n",
       "      <td>134.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>175.250000</td>\n",
       "      <td>163.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>466.000000</td>\n",
       "      <td>267.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       old_glucose     glucose\n",
       "count   220.000000  211.000000\n",
       "mean    149.947727  141.481043\n",
       "std      60.651774   43.870883\n",
       "min      62.000000   62.000000\n",
       "25%     108.000000  107.500000\n",
       "50%     136.500000  134.000000\n",
       "75%     175.250000  163.500000\n",
       "max     466.000000  267.000000"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cast to numeric values\n",
    "df_outlier = pd.DataFrame()\n",
    "df_outlier['glucose'] = pd.to_numeric(df_vitalsign['glucose'])\n",
    "\n",
    "# Store original temp for comparison at the end\n",
    "df_outlier['old_glucose'] = df_outlier['glucose']\n",
    "\n",
    "# Compute IQR\n",
    "q1 = df_outlier['glucose'].quantile(0.25)\n",
    "q3 = df_outlier['glucose'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "# Compute limits\n",
    "lower_limit = q1 - 1.5 * iqr\n",
    "upper_limit = q3 + 1.5 * iqr\n",
    "\n",
    "# Replace extreme values with NaN by using the mask function\n",
    "df_outlier['glucose'] = df_outlier['glucose'].mask(\n",
    "    (df_outlier['glucose'] < lower_limit) | (df_outlier['glucose'] > upper_limit))\n",
    "\n",
    "# Check the result\n",
    "df_outlier[['old_glucose','glucose']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ❓ Exercise 3.2 - Data Cleaning\n",
    "Clean as much of the `df_messy` data frame as you can. Copy from the previous exercises/examples where useful.\n",
    "\n",
    "Some of the columns in the data do not have an obvious way to impute them, you can use your judgement what to do with these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_messy = pd.read_csv(\"https://teaching.bowyer.io/SDSAI/3/data/messy_data.csv\")\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning Data Sets\n",
    "*   e.g. sample time, data types, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wrap Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Next Session\n",
    "*   Read chapters 12, 13, and 15 of the 'Secondary Analysis of Electronic Health Records' book (on the reading list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
